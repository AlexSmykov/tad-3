{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIANTS = ['food', 'non_food']\n",
    "IMAGE_SIZE = (256, 256)\n",
    "IMAGE_KERNEL_SIZE = (256, 256, 1)\n",
    "CLASSES_COUNT = len(VARIANTS)\n",
    "BATCH_SIZE = 8\n",
    "EPOCH_СOUNT = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_layers(hidden_layers_count, hidden_layers_sizes, activation_functions, filters_count, dropout_part):\n",
    "    layers = []\n",
    "\n",
    "    layers.append(tf.keras.layers.Rescaling(scale=1. / 255))\n",
    "    layers.append(tf.keras.layers.Conv2D(filters_count, (3, 3), activation='relu', input_shape=IMAGE_KERNEL_SIZE))\n",
    "    layers.append(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    layers.append(tf.keras.layers.Conv2D(filters_count, (3, 3), activation='relu'))\n",
    "    layers.append(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    layers.append(tf.keras.layers.Conv2D(filters_count, (3, 3), activation='relu'))\n",
    "    layers.append(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    layers.append(tf.keras.layers.Flatten())\n",
    "\n",
    "    for i in range(hidden_layers_count):\n",
    "        if activation_functions == \"lelu\":\n",
    "            layers.append(tf.keras.layers.Dense(hidden_layers_sizes))\n",
    "            layers.append(tf.keras.layers.LeakyReLU(0.2))\n",
    "        else:    \n",
    "            layers.append(tf.keras.layers.Dense(hidden_layers_sizes, activation=activation_functions))\n",
    "        layers.append(tf.keras.layers.Dropout(dropout_part))\n",
    "    \n",
    "    layers.append(tf.keras.layers.Dense(CLASSES_COUNT, activation='softmax'))\n",
    "    \n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_parameters = [\n",
    "    [2, 50, 'relu', 16, 0.12],\n",
    "    [3, 150, 'lelu', 32, 0.15],\n",
    "    [4, 500, 'relu', 64, 0.2],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_MODEL = 0\n",
    "\n",
    "selected_params = models_parameters[SELECTED_MODEL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 files belonging to 2 classes.\n",
      "625\n"
     ]
    }
   ],
   "source": [
    "ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    'dataset',\n",
    "    shuffle=True,\n",
    "    seed=69,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=BATCH_SIZE)\n",
    "\n",
    "ds_size = len(ds)\n",
    "print(ds_size)\n",
    "\n",
    "train_ds = ds.take(int(ds_size * 0.6))\n",
    "validation_ds = ds.skip(int(ds_size * 0.6)).take(int(ds_size * 0.2))\n",
    "test_ds = ds.skip(int(ds_size * 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid(model, current_ds):\n",
    "    grid = [[0, 0],\n",
    "            [0, 0]]\n",
    "\n",
    "    for test_pic_batch, test_val_batch in test_ds:\n",
    "        predictions = model.predict(test_pic_batch, verbose=0)\n",
    "        predicted_values = [np.argmax(prediction) for prediction in predictions]\n",
    "        test_values = test_val_batch.numpy().tolist()\n",
    "\n",
    "        for j in range(len(test_values)):\n",
    "            grid[predicted_values[j]][test_values[j]] += 1 \n",
    "\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_accuracy(grid=None, model=None, current_ds=None):\n",
    "    if not grid:\n",
    "        grid = get_grid(model, current_ds)\n",
    "\n",
    "    return float(grid[0][0] +  grid[1][1]) / float(grid[0][0] + grid[1][0] + grid[0][1] + grid[1][1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with parameters [2, 50, 'relu', 16, 0.12]\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 14s 37ms/step - loss: 0.6894 - accuracy: 0.5300 - val_loss: 0.6799 - val_accuracy: 0.6390\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.6720 - accuracy: 0.6020 - val_loss: 0.6526 - val_accuracy: 0.6570\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.6518 - accuracy: 0.6357 - val_loss: 0.6239 - val_accuracy: 0.6790\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.6267 - accuracy: 0.6640 - val_loss: 0.5971 - val_accuracy: 0.6960\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.6022 - accuracy: 0.6830 - val_loss: 0.5777 - val_accuracy: 0.7130\n",
      "<keras.src.callbacks.History object at 0x0000017BB18524D0>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model with parameters {selected_params}\")\n",
    "\n",
    "model = tf.keras.Sequential(create_layers(*selected_params))\n",
    "model.compile('Adagrad', \"sparse_categorical_crossentropy\", ['accuracy'])\n",
    "fit_result = model.fit(train_ds.cache(), validation_data=validation_ds.cache(), epochs=EPOCH_СOUNT)\n",
    "print(fit_result)\n",
    "grid = get_grid(model, test_ds)\n",
    "\n",
    "with open('result.json', 'w') as f:\n",
    "    json.dump({f'model {SELECTED_MODEL}': get_prediction_accuracy(grid)}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('models')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.mkdir(f'models/{SELECTED_MODEL}')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model.save_weights(f'models/{SELECTED_MODEL}/model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
